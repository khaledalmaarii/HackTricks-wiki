# LFI2RCE via Eternal waiting

{% hint style="success" %}
Learn & practice AWS Hacking:<img src="/.gitbook/assets/arte.png" alt="" data-size="line">[**HackTricks Training AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="/.gitbook/assets/arte.png" alt="" data-size="line">\
Learn & practice GCP Hacking: <img src="/.gitbook/assets/grte.png" alt="" data-size="line">[**HackTricks Training GCP Red Team Expert (GRTE)**<img src="/.gitbook/assets/grte.png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>Support HackTricks</summary>

* Check the [**subscription plans**](https://github.com/sponsors/carlospolop)!
* **Join the** üí¨ [**Discord group**](https://discord.gg/hRep4RUj7f) or the [**telegram group**](https://t.me/peass) or **follow** us on **Twitter** üê¶ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* **Share hacking tricks by submitting PRs to the** [**HackTricks**](https://github.com/carlospolop/hacktricks) and [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github repos.

</details>
{% endhint %}

## Basic Information

Por padr√£o, quando um arquivo √© enviado para o PHP (mesmo que n√£o esteja esperando por isso), ele gerar√° um arquivo tempor√°rio em `/tmp` com um nome como **`php[a-zA-Z0-9]{6}`**, embora eu tenha visto algumas imagens do docker onde os arquivos gerados n√£o cont√™m d√≠gitos.

Em uma inclus√£o de arquivo local, **se voc√™ conseguir incluir esse arquivo enviado, voc√™ obter√° RCE**.

Note que, por padr√£o, **o PHP s√≥ permite o upload de 20 arquivos em uma √∫nica solicita√ß√£o** (configurado em `/etc/php/<version>/apache2/php.ini`):
```
; Maximum number of files that can be uploaded via a single request
max_file_uploads = 20
```
Also, o **n√∫mero de nomes de arquivos potenciais √© 62\*62\*62\*62\*62\*62 = 56800235584**

### Outras t√©cnicas

Outras t√©cnicas dependem de atacar protocolos PHP (voc√™ n√£o conseguir√° se controlar apenas a √∫ltima parte do caminho), divulgar o caminho do arquivo, abusar de arquivos esperados, ou **fazer o PHP sofrer uma falha de segmenta√ß√£o para que arquivos tempor√°rios enviados n√£o sejam exclu√≠dos**.\
Esta t√©cnica √© **muito semelhante √† √∫ltima, mas sem precisar encontrar um zero day**.

### T√©cnica de espera eterna

Nesta t√©cnica **s√≥ precisamos controlar um caminho relativo**. Se conseguirmos enviar arquivos e fazer o **LFI nunca acabar**, teremos "tempo suficiente" para **for√ßar a for√ßa bruta de arquivos enviados** e **encontrar** qualquer um dos arquivos enviados.

**Pr√≥s desta t√©cnica**:

* Voc√™ s√≥ precisa controlar um caminho relativo dentro de um include
* N√£o requer nginx ou n√≠vel inesperado de acesso a arquivos de log
* N√£o requer um 0 day para causar uma falha de segmenta√ß√£o
* N√£o requer divulga√ß√£o de caminho

Os **principais problemas** desta t√©cnica s√£o:

* Necessidade de um arquivo(s) espec√≠fico(s) estar presente (pode haver mais)
* A **quantidade insana** de nomes de arquivos potenciais: **56800235584**
* Se o servidor **n√£o estiver usando d√≠gitos**, a quantidade total potencial √©: **19770609664**
* Por padr√£o, **apenas 20 arquivos** podem ser enviados em uma **√∫nica solicita√ß√£o**.
* O **n√∫mero m√°ximo de trabalhadores paralelos** do servidor utilizado.
* Este limite com os anteriores pode fazer este ataque durar demais
* **Timeout para uma solicita√ß√£o PHP**. Idealmente, isso deveria ser eterno ou deveria matar o processo PHP sem excluir os arquivos tempor√°rios enviados, caso contr√°rio, isso tamb√©m ser√° um problema

Ent√£o, como voc√™ pode **fazer um include PHP nunca acabar**? Basta incluir o arquivo **`/sys/kernel/security/apparmor/revision`** (**n√£o dispon√≠vel em cont√™ineres Docker** infelizmente...). 

Tente apenas chamando:
```bash
php -a # open php cli
include("/sys/kernel/security/apparmor/revision");
```
## Apache2

Por padr√£o, o Apache suporta **150 conex√µes simult√¢neas**, seguindo [https://ubiq.co/tech-blog/increase-max-connections-apache/](https://ubiq.co/tech-blog/increase-max-connections-apache/) √© poss√≠vel aumentar esse n√∫mero para at√© 8000. Siga isso para usar PHP com esse m√≥dulo: [https://www.digitalocean.com/community/tutorials/how-to-configure-apache-http-with-mpm-event-and-php-fpm-on-ubuntu-18-04](https://www.digitalocean.com/community/tutorials/how-to-configure-apache-http-with-mpm-event-and-php-fpm-on-ubuntu-18-04).

Por padr√£o, (como posso ver em meus testes), um **processo PHP pode durar eternamente**.

Vamos fazer algumas contas:

* Podemos usar **149 conex√µes** para gerar **149 \* 20 = 2980 arquivos tempor√°rios** com nosso webshell.
* Em seguida, use a **√∫ltima conex√£o** para **for√ßar** arquivos potenciais.
* A uma velocidade de **10 requisi√ß√µes/s**, os tempos s√£o:
* 56800235584 / 2980 / 10 / 3600 \~= **530 horas** (50% de chance em 265h)
* (sem d√≠gitos) 19770609664 / 2980 / 10 / 3600 \~= 185h (50% de chance em 93h)

{% hint style="warning" %}
Note que no exemplo anterior estamos **completamente DoSing outros clientes**!
{% endhint %}

Se o servidor Apache for melhorado e pudermos abusar de **4000 conex√µes** (metade do n√∫mero m√°ximo). Poder√≠amos criar `3999*20 = 79980` **arquivos** e o **n√∫mero** seria **reduzido** para cerca de **19.7h** ou **6.9h** (10h, 3.5h 50% de chance).

## PHP-FMP

Se em vez de usar o mod php regular para apache para executar scripts PHP, a **p√°gina da web est√° usando** **PHP-FMP** (isso melhora a efici√™ncia da p√°gina da web, ent√£o √© comum encontr√°-lo), h√° algo mais que pode ser feito para melhorar a t√©cnica.

PHP-FMP permite **configurar** o **par√¢metro** **`request_terminate_timeout`** em **`/etc/php/<php-version>/fpm/pool.d/www.conf`**.\
Esse par√¢metro indica a quantidade m√°xima de segundos **quando** **a requisi√ß√£o ao PHP deve terminar** (infinito por padr√£o, mas **30s se o par√¢metro for descomentado**). Quando uma requisi√ß√£o est√° sendo processada pelo PHP, o n√∫mero indicado de segundos √© **morto**. Isso significa que, se a requisi√ß√£o estava fazendo upload de arquivos tempor√°rios, porque o **processamento php foi interrompido**, esses **arquivos n√£o ser√£o deletados**. Portanto, se voc√™ conseguir fazer uma requisi√ß√£o durar esse tempo, pode **gerar milhares de arquivos tempor√°rios** que n√£o ser√£o deletados, o que **acelerar√° o processo de encontr√°-los** e reduz a probabilidade de um DoS na plataforma consumindo todas as conex√µes.

Ent√£o, para **evitar DoS**, vamos supor que um **atacante estar√° usando apenas 100 conex√µes** ao mesmo tempo e o tempo m√°ximo de processamento php por **php-fmp** (`request_terminate_timeout`**)** √© **30s**. Portanto, o n√∫mero de **arquivos tempor√°rios** que podem ser gerados **por segundo** √© `100*20/30 = 66.67`.

Ent√£o, para gerar **10000 arquivos**, um atacante precisaria: **`10000/66.67 = 150s`** (para gerar **100000 arquivos** o tempo seria **25min**).

Ent√£o, o atacante poderia usar essas **100 conex√µes** para realizar uma **busca brute-force**. \*\*\*\* Supondo uma velocidade de 300 req/s, o tempo necess√°rio para explorar isso √© o seguinte:

* 56800235584 / 10000 / 300 / 3600 \~= **5.25 horas** (50% de chance em 2.63h)
* (com 100000 arquivos) 56800235584 / 100000 / 300 / 3600 \~= **0.525 horas** (50% de chance em 0.263h)

Sim, √© poss√≠vel gerar 100000 arquivos tempor√°rios em uma inst√¢ncia EC2 de tamanho m√©dio:

<figure><img src="../../.gitbook/assets/image (240).png" alt=""><figcaption></figcaption></figure>

{% hint style="warning" %}
Note que para acionar o timeout seria **suficiente incluir a p√°gina LFI vulner√°vel**, para que entre em um loop de inclus√£o eterno.
{% endhint %}

## Nginx

Parece que por padr√£o o Nginx suporta **512 conex√µes paralelas** ao mesmo tempo (e esse n√∫mero pode ser melhorado).

{% hint style="success" %}
Learn & practice AWS Hacking:<img src="/.gitbook/assets/arte.png" alt="" data-size="line">[**HackTricks Training AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="/.gitbook/assets/arte.png" alt="" data-size="line">\
Learn & practice GCP Hacking: <img src="/.gitbook/assets/grte.png" alt="" data-size="line">[**HackTricks Training GCP Red Team Expert (GRTE)**<img src="/.gitbook/assets/grte.png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>Support HackTricks</summary>

* Check the [**subscription plans**](https://github.com/sponsors/carlospolop)!
* **Join the** üí¨ [**Discord group**](https://discord.gg/hRep4RUj7f) or the [**telegram group**](https://t.me/peass) or **follow** us on **Twitter** üê¶ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* **Share hacking tricks by submitting PRs to the** [**HackTricks**](https://github.com/carlospolop/hacktricks) and [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github repos.

</details>
{% endhint %}
