# LFI2RCE via Eternal waiting

{% hint style="success" %}
Learn & practice AWS Hacking:<img src="/.gitbook/assets/arte.png" alt="" data-size="line">[**HackTricks Training AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="/.gitbook/assets/arte.png" alt="" data-size="line">\
Learn & practice GCP Hacking: <img src="/.gitbook/assets/grte.png" alt="" data-size="line">[**HackTricks Training GCP Red Team Expert (GRTE)**<img src="/.gitbook/assets/grte.png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>Support HackTricks</summary>

* Check the [**subscription plans**](https://github.com/sponsors/carlospolop)!
* **Join the** üí¨ [**Discord group**](https://discord.gg/hRep4RUj7f) or the [**telegram group**](https://t.me/peass) or **follow** us on **Twitter** üê¶ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* **Share hacking tricks by submitting PRs to the** [**HackTricks**](https://github.com/carlospolop/hacktricks) and [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github repos.

</details>
{% endhint %}

## Informaci√≥n B√°sica

Por defecto, cuando se sube un archivo a PHP (incluso si no lo est√° esperando), generar√° un archivo temporal en `/tmp` con un nombre como **`php[a-zA-Z0-9]{6}`**, aunque he visto algunas im√°genes de docker donde los archivos generados no contienen d√≠gitos.

En una inclusi√≥n de archivo local, **si logras incluir ese archivo subido, obtendr√°s RCE**.

Ten en cuenta que por defecto **PHP solo permite subir 20 archivos en una sola solicitud** (configurado en `/etc/php/<version>/apache2/php.ini`):
```
; Maximum number of files that can be uploaded via a single request
max_file_uploads = 20
```
Tambi√©n, el **n√∫mero de nombres de archivo potenciales es 62\*62\*62\*62\*62\*62 = 56800235584**

### Otras t√©cnicas

Otras t√©cnicas se basan en atacar protocolos de PHP (no podr√°s si solo controlas la √∫ltima parte de la ruta), divulgar la ruta del archivo, abusar de archivos esperados, o **hacer que PHP sufra un fallo de segmentaci√≥n para que los archivos temporales subidos no sean eliminados**.\
Esta t√©cnica es **muy similar a la √∫ltima pero sin necesidad de encontrar un zero day**.

### T√©cnica de espera eterna

En esta t√©cnica **solo necesitamos controlar una ruta relativa**. Si logramos subir archivos y hacer que el **LFI nunca termine**, tendremos "suficiente tiempo" para **fuerza bruta de archivos subidos** y **encontrar** cualquiera de los que se hayan subido.

**Ventajas de esta t√©cnica**:

* Solo necesitas controlar una ruta relativa dentro de un include
* No requiere nginx ni un nivel inesperado de acceso a archivos de registro
* No requiere un 0 day para causar un fallo de segmentaci√≥n
* No requiere divulgaci√≥n de ruta

Los **principales problemas** de esta t√©cnica son:

* Necesita que un archivo(s) espec√≠fico(s) est√©(n) presente(s) (puede haber m√°s)
* La **incre√≠ble** cantidad de nombres de archivo potenciales: **56800235584**
* Si el servidor **no est√° usando d√≠gitos**, la cantidad total potencial es: **19770609664**
* Por defecto, **solo se pueden subir 20 archivos** en una **sola solicitud**.
* El **n√∫mero m√°ximo de trabajadores paralelos** del servidor utilizado.
* Este l√≠mite junto con los anteriores puede hacer que este ataque dure demasiado
* **Tiempo de espera para una solicitud PHP**. Idealmente, esto deber√≠a ser eterno o deber√≠a matar el proceso PHP sin eliminar los archivos temporales subidos, si no, esto tambi√©n ser√° un problema

Entonces, ¬øc√≥mo puedes **hacer que un include de PHP nunca termine**? Simplemente incluyendo el archivo **`/sys/kernel/security/apparmor/revision`** (**no disponible en contenedores Docker** desafortunadamente...). 

Int√©ntalo simplemente llamando:
```bash
php -a # open php cli
include("/sys/kernel/security/apparmor/revision");
```
## Apache2

Por defecto, Apache soporta **150 conexiones concurrentes**, siguiendo [https://ubiq.co/tech-blog/increase-max-connections-apache/](https://ubiq.co/tech-blog/increase-max-connections-apache/) es posible aumentar este n√∫mero hasta 8000. Sigue esto para usar PHP con ese m√≥dulo: [https://www.digitalocean.com/community/tutorials/how-to-configure-apache-http-with-mpm-event-and-php-fpm-on-ubuntu-18-04](https://www.digitalocean.com/community/tutorials/how-to-configure-apache-http-with-mpm-event-and-php-fpm-on-ubuntu-18-04).

Por defecto, (como puedo ver en mis pruebas), un **proceso PHP puede durar eternamente**.

Hagamos algunos c√°lculos:

* Podemos usar **149 conexiones** para generar **149 \* 20 = 2980 archivos temporales** con nuestro webshell.
* Luego, usar la **√∫ltima conexi√≥n** para **fuerza bruta** de archivos potenciales.
* A una velocidad de **10 solicitudes/s** los tiempos son:
* 56800235584 / 2980 / 10 / 3600 \~= **530 horas** (50% de probabilidad en 265h)
* (sin d√≠gitos) 19770609664 / 2980 / 10 / 3600 \~= 185h (50% de probabilidad en 93h)

{% hint style="warning" %}
¬°Ten en cuenta que en el ejemplo anterior estamos **completamente DoSing a otros clientes**!
{% endhint %}

Si el servidor Apache se mejora y pudi√©ramos abusar de **4000 conexiones** (a medio camino del n√∫mero m√°ximo). Podr√≠amos crear `3999*20 = 79980` **archivos** y el **n√∫mero** se reducir√≠a a alrededor de **19.7h** o **6.9h** (10h, 3.5h 50% de probabilidad).

## PHP-FMP

Si en lugar de usar el m√≥dulo php regular para apache para ejecutar scripts PHP, la **p√°gina web est√° usando** **PHP-FMP** (esto mejora la eficiencia de la p√°gina web, por lo que es com√∫n encontrarlo), hay algo m√°s que se puede hacer para mejorar la t√©cnica.

PHP-FMP permite **configurar** el **par√°metro** **`request_terminate_timeout`** en **`/etc/php/<php-version>/fpm/pool.d/www.conf`**.\
Este par√°metro indica la cantidad m√°xima de segundos **cuando** **la solicitud a PHP debe terminar** (infinito por defecto, pero **30s si el par√°metro est√° descomentado**). Cuando una solicitud est√° siendo procesada por PHP el n√∫mero de segundos indicado, es **eliminada**. Esto significa que, si la solicitud estaba subiendo archivos temporales, porque el **procesamiento de PHP fue detenido**, esos **archivos no se van a eliminar**. Por lo tanto, si puedes hacer que una solicitud dure ese tiempo, puedes **generar miles de archivos temporales** que no ser√°n eliminados, lo que **acelerar√° el proceso de encontrarlos** y reduce la probabilidad de un DoS a la plataforma consumiendo todas las conexiones.

Entonces, para **evitar DoS** supongamos que un **atacante estar√° usando solo 100 conexiones** al mismo tiempo y el tiempo m√°ximo de procesamiento de PHP por **php-fmp** (`request_terminate_timeout`**)** es **30s**. Por lo tanto, el n√∫mero de **archivos temporales** que se pueden generar **por segundo** es `100*20/30 = 66.67`.

Luego, para generar **10000 archivos** un atacante necesitar√≠a: **`10000/66.67 = 150s`** (para generar **100000 archivos** el tiempo ser√≠a **25min**).

Luego, el atacante podr√≠a usar esas **100 conexiones** para realizar una **b√∫squeda de fuerza bruta**. \*\*\*\* Suponiendo una velocidad de 300 req/s el tiempo necesario para explotar esto es el siguiente:

* 56800235584 / 10000 / 300 / 3600 \~= **5.25 horas** (50% de probabilidad en 2.63h)
* (con 100000 archivos) 56800235584 / 100000 / 300 / 3600 \~= **0.525 horas** (50% de probabilidad en 0.263h)

S√≠, es posible generar 100000 archivos temporales en una instancia de tama√±o medio de EC2:

<figure><img src="../../.gitbook/assets/image (240).png" alt=""><figcaption></figcaption></figure>

{% hint style="warning" %}
Ten en cuenta que para activar el tiempo de espera ser√≠a **suficiente incluir la p√°gina LFI vulnerable**, para que entre en un bucle de inclusi√≥n eterno.
{% endhint %}

## Nginx

Parece que por defecto Nginx soporta **512 conexiones paralelas** al mismo tiempo (y este n√∫mero puede mejorarse).

{% hint style="success" %}
Aprende y practica Hacking en AWS:<img src="/.gitbook/assets/arte.png" alt="" data-size="line">[**HackTricks Training AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="/.gitbook/assets/arte.png" alt="" data-size="line">\
Aprende y practica Hacking en GCP: <img src="/.gitbook/assets/grte.png" alt="" data-size="line">[**HackTricks Training GCP Red Team Expert (GRTE)**<img src="/.gitbook/assets/grte.png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>Apoya a HackTricks</summary>

* Revisa los [**planes de suscripci√≥n**](https://github.com/sponsors/carlospolop)!
* **√önete al** üí¨ [**grupo de Discord**](https://discord.gg/hRep4RUj7f) o al [**grupo de telegram**](https://t.me/peass) o **s√≠guenos** en **Twitter** üê¶ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* **Comparte trucos de hacking enviando PRs a los** [**HackTricks**](https://github.com/carlospolop/hacktricks) y [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) repositorios de github.

</details>
{% endhint %}
