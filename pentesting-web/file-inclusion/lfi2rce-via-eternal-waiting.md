# LFI2RCE via Eternal waiting

{% hint style="success" %}
Learn & practice AWS Hacking:<img src="/.gitbook/assets/arte.png" alt="" data-size="line">[**HackTricks Training AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="/.gitbook/assets/arte.png" alt="" data-size="line">\
Learn & practice GCP Hacking: <img src="/.gitbook/assets/grte.png" alt="" data-size="line">[**HackTricks Training GCP Red Team Expert (GRTE)**<img src="/.gitbook/assets/grte.png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>Support HackTricks</summary>

* Check the [**subscription plans**](https://github.com/sponsors/carlospolop)!
* **Join the** üí¨ [**Discord group**](https://discord.gg/hRep4RUj7f) or the [**telegram group**](https://t.me/peass) or **follow** us on **Twitter** üê¶ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* **Share hacking tricks by submitting PRs to the** [**HackTricks**](https://github.com/carlospolop/hacktricks) and [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github repos.

</details>
{% endhint %}

## Informations de base

Par d√©faut, lorsqu'un fichier est t√©l√©charg√© sur PHP (m√™me s'il ne s'y attend pas), il g√©n√©rera un fichier temporaire dans `/tmp` avec un nom tel que **`php[a-zA-Z0-9]{6}`**, bien que j'aie vu certaines images docker o√π les fichiers g√©n√©r√©s ne contiennent pas de chiffres.

Dans une inclusion de fichier local, **si vous parvenez √† inclure ce fichier t√©l√©charg√©, vous obtiendrez RCE**.

Notez qu'en r√®gle g√©n√©rale, **PHP n'autorise que le t√©l√©chargement de 20 fichiers dans une seule requ√™te** (d√©fini dans `/etc/php/<version>/apache2/php.ini`):
```
; Maximum number of files that can be uploaded via a single request
max_file_uploads = 20
```
Aussi, le **nombre de noms de fichiers potentiels est 62\*62\*62\*62\*62\*62 = 56800235584**

### Autres techniques

D'autres techniques reposent sur l'attaque des protocoles PHP (vous ne pourrez pas le faire si vous ne contr√¥lez que la derni√®re partie du chemin), la divulgation du chemin du fichier, l'abus de fichiers attendus, ou **faire souffrir PHP d'un d√©faut de segmentation afin que les fichiers temporaires t√©l√©charg√©s ne soient pas supprim√©s**.\
Cette technique est **tr√®s similaire √† la derni√®re mais sans avoir besoin de trouver un zero day**.

### Technique de l'attente √©ternelle

Dans cette technique, **nous n'avons besoin de contr√¥ler qu'un chemin relatif**. Si nous parvenons √† t√©l√©charger des fichiers et √† faire en sorte que le **LFI ne se termine jamais**, nous aurons "assez de temps" pour **brute-forcer les fichiers t√©l√©charg√©s** et **trouver** n'importe lequel des fichiers t√©l√©charg√©s.

**Avantages de cette technique** :

* Vous devez juste contr√¥ler un chemin relatif √† l'int√©rieur d'un include
* Ne n√©cessite pas nginx ou un niveau d'acc√®s inattendu aux fichiers journaux
* Ne n√©cessite pas un 0 day pour provoquer un d√©faut de segmentation
* Ne n√©cessite pas de divulgation de chemin

Les **principaux probl√®mes** de cette technique sont :

* Besoin d'un fichier sp√©cifique (il peut y en avoir d'autres)
* L'**√©norme** quantit√© de noms de fichiers potentiels : **56800235584**
* Si le serveur **n'utilise pas de chiffres**, le nombre total potentiel est : **19770609664**
* Par d√©faut, **seulement 20 fichiers** peuvent √™tre t√©l√©charg√©s dans une **unique requ√™te**.
* Le **nombre max de travailleurs parall√®les** du serveur utilis√©.
* Cette limite avec les pr√©c√©dentes peut faire durer cette attaque trop longtemps
* **D√©lai d'attente pour une requ√™te PHP**. Id√©alement, cela devrait √™tre √©ternel ou devrait tuer le processus PHP sans supprimer les fichiers temporaires t√©l√©charg√©s, sinon, cela sera √©galement un probl√®me

Alors, comment pouvez-vous **faire en sorte qu'un include PHP ne se termine jamais** ? Juste en incluant le fichier **`/sys/kernel/security/apparmor/revision`** (**non disponible dans les conteneurs Docker** malheureusement...). 

Essayez-le simplement en appelant :
```bash
php -a # open php cli
include("/sys/kernel/security/apparmor/revision");
```
## Apache2

Par d√©faut, Apache supporte **150 connexions simultan√©es**, suivant [https://ubiq.co/tech-blog/increase-max-connections-apache/](https://ubiq.co/tech-blog/increase-max-connections-apache/) il est possible d'augmenter ce nombre jusqu'√† 8000. Suivez ceci pour utiliser PHP avec ce module : [https://www.digitalocean.com/community/tutorials/how-to-configure-apache-http-with-mpm-event-and-php-fpm-on-ubuntu-18-04](https://www.digitalocean.com/community/tutorials/how-to-configure-apache-http-with-mpm-event-and-php-fpm-on-ubuntu-18-04).

Par d√©faut, (comme je peux le voir dans mes tests), un **processus PHP peut durer √©ternellement**.

Faisons quelques calculs :

* Nous pouvons utiliser **149 connexions** pour g√©n√©rer **149 \* 20 = 2980 fichiers temporaires** avec notre webshell.
* Ensuite, utilisez la **derni√®re connexion** pour **brute-forcer** des fichiers potentiels.
* √Ä une vitesse de **10 requ√™tes/s**, les temps sont :
* 56800235584 / 2980 / 10 / 3600 \~= **530 heures** (50% de chance en 265h)
* (sans chiffres) 19770609664 / 2980 / 10 / 3600 \~= 185h (50% de chance en 93h)

{% hint style="warning" %}
Notez que dans l'exemple pr√©c√©dent, nous **DoS compl√®tement d'autres clients** !
{% endhint %}

Si le serveur Apache est am√©lior√© et que nous pouvions abuser de **4000 connexions** (√† mi-chemin du nombre maximum). Nous pourrions cr√©er `3999*20 = 79980` **fichiers** et le **nombre** serait **r√©duit** √† environ **19.7h** ou **6.9h** (10h, 3.5h 50% de chance).

## PHP-FMP

Si au lieu d'utiliser le mod php r√©gulier pour apache pour ex√©cuter des scripts PHP, la **page web utilise** **PHP-FMP** (cela am√©liore l'efficacit√© de la page web, donc il est courant de le trouver), il y a autre chose qui peut √™tre fait pour am√©liorer la technique.

PHP-FMP permet de **configurer** le **param√®tre** **`request_terminate_timeout`** dans **`/etc/php/<version-php>/fpm/pool.d/www.conf`**.\
Ce param√®tre indique le nombre maximum de secondes **quand** **la requ√™te √† PHP doit se terminer** (infini par d√©faut, mais **30s si le param√®tre est d√©comment√©**). Lorsqu'une requ√™te est trait√©e par PHP pendant le nombre de secondes indiqu√©, elle est **tu√©e**. Cela signifie que si la requ√™te t√©l√©chargeait des fichiers temporaires, parce que le **traitement PHP a √©t√© arr√™t√©**, ces **fichiers ne seront pas supprim√©s**. Par cons√©quent, si vous pouvez faire durer une requ√™te ce temps, vous pouvez **g√©n√©rer des milliers de fichiers temporaires** qui ne seront pas supprim√©s, ce qui **acc√©l√©rera le processus de les trouver** et r√©duit la probabilit√© d'un DoS √† la plateforme en consommant toutes les connexions.

Donc, pour **√©viter le DoS**, supposons qu'un **attaquant n'utilisera que 100 connexions** en m√™me temps et que le temps de traitement maximum par **php-fmp** (`request_terminate_timeout`**)** est **30s**. Par cons√©quent, le nombre de **fichiers temporaires** qui peuvent √™tre g√©n√©r√©s **par seconde** est `100*20/30 = 66.67`.

Ensuite, pour g√©n√©rer **10000 fichiers**, un attaquant aurait besoin de : **`10000/66.67 = 150s`** (pour g√©n√©rer **100000 fichiers**, le temps serait de **25min**).

Ensuite, l'attaquant pourrait utiliser ces **100 connexions** pour effectuer une **recherche brute-force**. \*\*\*\* Supposant une vitesse de 300 req/s, le temps n√©cessaire pour exploiter cela est le suivant :

* 56800235584 / 10000 / 300 / 3600 \~= **5.25 heures** (50% de chance en 2.63h)
* (avec 100000 fichiers) 56800235584 / 100000 / 300 / 3600 \~= **0.525 heures** (50% de chance en 0.263h)

Oui, il est possible de g√©n√©rer 100000 fichiers temporaires dans une instance EC2 de taille moyenne :

<figure><img src="../../.gitbook/assets/image (240).png" alt=""><figcaption></figcaption></figure>

{% hint style="warning" %}
Notez que pour d√©clencher le timeout, il suffirait d'inclure la page LFI vuln√©rable, afin qu'elle entre dans une boucle d'inclusion √©ternelle.
{% endhint %}

## Nginx

Il semble qu'en par d√©faut, Nginx supporte **512 connexions parall√®les** en m√™me temps (et ce nombre peut √™tre am√©lior√©).

{% hint style="success" %}
Apprenez et pratiquez le hacking AWS :<img src="/.gitbook/assets/arte.png" alt="" data-size="line">[**HackTricks Training AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="/.gitbook/assets/arte.png" alt="" data-size="line">\
Apprenez et pratiquez le hacking GCP : <img src="/.gitbook/assets/grte.png" alt="" data-size="line">[**HackTricks Training GCP Red Team Expert (GRTE)**<img src="/.gitbook/assets/grte.png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>Support HackTricks</summary>

* Consultez les [**plans d'abonnement**](https://github.com/sponsors/carlospolop) !
* **Rejoignez le** üí¨ [**groupe Discord**](https://discord.gg/hRep4RUj7f) ou le [**groupe telegram**](https://t.me/peass) ou **suivez-nous sur** **Twitter** üê¶ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* **Partagez des astuces de hacking en soumettant des PRs aux** [**HackTricks**](https://github.com/carlospolop/hacktricks) et [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) d√©p√¥ts github.

</details>
{% endhint %}
